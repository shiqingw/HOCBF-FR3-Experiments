{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def depth2PointCloud(depth_map, fx, fy, cx, cy, min_depth=0.2, max_depth=3.0, depth_scale=1000.0):\n",
    "    rows, cols = depth_map.shape\n",
    "    # Apply the median filter to the depth image\n",
    "    depth = cv2.medianBlur(depth_map, ksize=3)\n",
    "    depth = depth.astype(np.float32)/depth_scale\n",
    "    # depth = np.clip(depth, min_depth, max_depth)\n",
    "    # Remove the outliers\n",
    "    idx = np.where(((depth.reshape(-1)<=min_depth)+(depth.reshape(-1)>=max_depth)))[0]\n",
    "    \n",
    "    # Create a mesh grid for the depth map\n",
    "    mesh_x, mesh_y = np.meshgrid(np.arange(cols), np.arange(rows))\n",
    "    np.where(depth_map > 3)\n",
    "    f = (fx+fy)/2\n",
    "    # Calculate 3D coordinates (X, Y, Z) from depth values\n",
    "    x = (mesh_x - cx) * depth_map / f\n",
    "    y = (mesh_y - cy) * depth_map / f\n",
    "    z = depth_map\n",
    "    point_cloud = np.stack((x, y, z), axis=-1).reshape(-1, 3)\n",
    "    point_cloud = np.delete(point_cloud, idx, axis=0)\n",
    "    return point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/sep26/camera_params.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdataset/sep26/camera_params.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     params \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m int_params \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mint_params\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/sep26/camera_params.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('dataset/sep26/camera_params.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "int_params = params['int_params']\n",
    "ext_params = params['ext_params']\n",
    "fx, fy, cx, cy = int_params['Depth']['fx'], int_params['Depth']['fy'], int_params['Depth']['cx'], int_params['Depth']['cy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "depth1 = cv2.imread('dataset/sep26/seq1/depth/1695784268680308480.png', -1)\n",
    "depth2 = cv2.imread('dataset/sep26/seq1/depth/1695784281219218432.png', -1)\n",
    "\n",
    "pc1 = depth2PointCloud(depth1,fx, fy, cx, cy).copy()\n",
    "pc2 = depth2PointCloud(depth2,fx, fy, cx, cy).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1 = np.hstack([pc1, np.ones((pc1.shape[0], 1))])\n",
    "pc2 = np.hstack([pc2, np.ones((pc2.shape[0], 1))])\n",
    "\n",
    "base_T1_ef = np.loadtxt('dataset/sep26/seq1/pose/1695784268680308480.txt')\n",
    "base_T2_ef = np.loadtxt('dataset/sep26/seq1/pose/1695784281219218432.txt')\n",
    "\n",
    "rgb_T1_tag = np.loadtxt('dataset/sep26/seq1/apriltag_pose/1695784268680308480.txt')\n",
    "rgb_T2_tag = np.loadtxt('dataset/sep26/seq1/apriltag_pose/1695784281219218432.txt')\n",
    "\n",
    "tag_T1_rgb = np.linalg.inv(rgb_T1_tag)\n",
    "tag_T2_rgb = np.linalg.inv(rgb_T2_tag)\n",
    "\n",
    "depth_T_rgb = ext_params['ir1_T_rgb']\n",
    "rgb_T_depth = np.linalg.inv(depth_T_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_pc1 = ((tag_T1_rgb@rgb_T_depth@pc1.T).T)[:,0:3]\n",
    "tag_pc2 = ((tag_T2_rgb@rgb_T_depth@pc2.T).T)[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "pcd1.points = o3d.utility.Vector3dVector(pc1[:,0:3])\n",
    "tag_pcd1 = o3d.geometry.PointCloud()\n",
    "tag_pcd1.points = o3d.utility.Vector3dVector(tag_pc1[:,0:3])\n",
    "\n",
    "pcd2 = o3d.geometry.PointCloud()\n",
    "pcd2.points = o3d.utility.Vector3dVector(pc2[:,0:3])\n",
    "tag_pcd2 = o3d.geometry.PointCloud()\n",
    "tag_pcd2.points = o3d.utility.Vector3dVector(tag_pc2[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd1,pcd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([tag_pcd1, tag_pcd2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling streams for camera:  216322074479\n"
     ]
    }
   ],
   "source": [
    "from FR3Py.vision.cameras import RealSenseCamera\n",
    "camera = RealSenseCamera(VGA=True, enable_imu=False, enable_ir=True, emitter_enabled=True, align_to_color=False, color_fps=30, depth_fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/robocaster/projects/manipulation/FR3Py/FR3Py/vision/cameras.py\", line 123, in _run_grab_frames\n",
      "    self.grab_frames()\n",
      "  File \"/home/robocaster/projects/manipulation/FR3Py/FR3Py/vision/cameras.py\", line 141, in grab_frames\n",
      "    frames = self.pipeline.wait_for_frames()\n",
      "RuntimeError: Frame didn't arrive within 5000\n"
     ]
    }
   ],
   "source": [
    "K = camera.getIntrinsics()['Depth']\n",
    "fx,fy,cx,cy = K['fx'], K['fy'], K['cx'], K['cy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Frame didn't arrive within 5000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopen3d\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mo3d\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m camera\u001b[39m.\u001b[39;49mgrab_frames()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m depth \u001b[39m=\u001b[39m camera\u001b[39m.\u001b[39mdepth_frame\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pc \u001b[39m=\u001b[39m depth2PointCloud(depth,fx, fy, cx, cy)\n",
      "File \u001b[0;32m~/projects/manipulation/FR3Py/FR3Py/vision/cameras.py:141\u001b[0m, in \u001b[0;36mRealSenseCamera.grab_frames\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrab_frames\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    138\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m    Grabs frames from the RealSense camera and stores them in instance variables.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mwait_for_frames()\n\u001b[1;32m    142\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malign_to_color:\n\u001b[1;32m    143\u001b[0m         frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malign\u001b[39m.\u001b[39mprocess(frames)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Frame didn't arrive within 5000"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "camera.grab_frames()\n",
    "depth = camera.depth_frame\n",
    "pc = depth2PointCloud(depth,fx, fy, cx, cy)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Frame didn't arrive within 5000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     camera\u001b[39m.\u001b[39;49mgrab_frames()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     depth \u001b[39m=\u001b[39m camera\u001b[39m.\u001b[39mdepth_frame\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/robocaster/projects/manipulation/FR3Py/examples/pointcloud_alignment_example.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     pc \u001b[39m=\u001b[39m depth2PointCloud(depth,fx, fy, cx, cy)\n",
      "File \u001b[0;32m~/projects/manipulation/FR3Py/FR3Py/vision/cameras.py:141\u001b[0m, in \u001b[0;36mRealSenseCamera.grab_frames\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrab_frames\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    138\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m    Grabs frames from the RealSense camera and stores them in instance variables.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mwait_for_frames()\n\u001b[1;32m    142\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malign_to_color:\n\u001b[1;32m    143\u001b[0m         frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malign\u001b[39m.\u001b[39mprocess(frames)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Frame didn't arrive within 5000"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "camera.grab_frames()\n",
    "depth = camera.depth_frame\n",
    "pc = depth2PointCloud(depth,fx, fy, cx, cy)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "\n",
    "while True:\n",
    "    time.sleep(0.01)\n",
    "    camera.grab_frames()\n",
    "    depth = camera.depth_frame\n",
    "    pc = depth2PointCloud(depth,fx, fy, cx, cy)\n",
    "    pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
